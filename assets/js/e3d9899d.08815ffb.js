"use strict";(self.webpackChunkprem_docs=self.webpackChunkprem_docs||[]).push([[7842],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>h});var a=t(67294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=a.createContext({}),p=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},c=function(e){var n=p(e.components);return a.createElement(l.Provider,{value:n},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},d=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=p(t),d=r,h=u["".concat(l,".").concat(d)]||u[d]||m[d]||o;return t?a.createElement(h,i(i({ref:n},c),{},{components:t})):a.createElement(h,i({ref:n},c))}));function h(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,i=new Array(o);i[0]=d;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[u]="string"==typeof e?e:r,i[1]=s;for(var p=2;p<o;p++)i[p]=t[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}d.displayName="MDXCreateElement"},44417:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>p});var a=t(87462),r=(t(67294),t(3905));const o={sidebar_position:3},i="Langchain: Talk to your Data",s={unversionedId:"prem-app/examples/langchain-talk-to-your-data",id:"prem-app/examples/langchain-talk-to-your-data",title:"Langchain: Talk to your Data",description:"- Install the necessary dependencies",source:"@site/docs/prem-app/examples/langchain-talk-to-your-data.md",sourceDirName:"prem-app/examples",slug:"/prem-app/examples/langchain-talk-to-your-data",permalink:"/docs/prem-app/examples/langchain-talk-to-your-data",draft:!1,editUrl:"https://github.com/premAI-io/dev-portal/docs/prem-app/examples/langchain-talk-to-your-data.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Examples",permalink:"/docs/category/examples"},next:{title:"Llama Index: Talk to your Data",permalink:"/docs/prem-app/examples/llama-index-talk-to-your-data"}},l={},p=[],c={toc:p},u="wrapper";function m(e){let{components:n,...t}=e;return(0,r.kt)(u,(0,a.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"langchain-talk-to-your-data"},"Langchain: Talk to your Data"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Install the necessary dependencies")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import os\n\nfrom langchain.chains import LLMChain\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.docstore.document import Document\nfrom langchain.vectorstores import Qdrant\nfrom langchain.vectorstores.redis import Redis\nfrom langchain.prompts import PromptTemplate\n\nos.environ["OPENAI_API_KEY"] = "random-string"\n')),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Create the Documents using Prem Landing Page Content\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'doc1 = Document(page_content="Prem is an easy to use open source AI platform. With Prem you can quickly build provacy preserving AI applications.")\ndoc2 = Document(page_content="""\nPrem App\n\nAn intuitive desktop application designed to effortlessly deploy and self-host Open-Source AI models without exposing sensitive data to third-party.\n\n""")\ndoc3 = Document(page_content="""\nPrem Benefits\n\nEffortless Integration\nSeamlessly implement machine learning models with the user-friendly interface of OpenAI\'s API.\n\nReady for the Real World\nBypass the complexities of inference optimizations. Prem\'s got you covered.\n\nRapid Iterations, Instant Results\nDevelop, test, and deploy your models in just minutes.\n\nPrivacy Above All\nYour keys, your models. We ensure end-to-end encryption.\n\nComprehensive Documentation\nDive into our rich resources and learn how to make the most of Prem.\n\nPreserve Your Anonymity\nMake payments with Bitcoin and Cryptocurrency. It\'s a permissionless infrastructure, designed for you.\n""")\n')),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Using QDrant, Vicuna and Sentence Transformers Running Locally using Prem")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Using vicuna-7b-q4\nchat = ChatOpenAI(openai_api_base="http://localhost:8111/api/v1", max_tokens=128)\n\n# Using sentence transformers all-MiniLM-L6-v2\nembeddings = OpenAIEmbeddings(openai_api_base="http://localhost:8444/api/v1")\n\n# Using locally running Qdrant\nurl = "http://localhost:6333"\n\nvectorstore = Qdrant.from_documents(\n    [doc1, doc2, doc3], \n    embeddings, \n    url=url, \n    collection_name="prem_collection_test",\n)\n\nquery = "What are Prem Benefits?"\ndocs = vectorstore.similarity_search(query)\nprint(docs[0].page_content)\n')),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Perform the Query")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'template = """\nYou are an AI assistant for answering questions about Prem.\nProvide a conversational answer to the question based on the following docouments found using semantic search. Be original, concice, accurate and helpful.\n\nQuestion: {question}\n=========\nContext: {context}\n=========\nAnswer in Markdown:\n"""  # noqa E501\nprompt = PromptTemplate(\n    input_variables=["question", "context"],\n    template=template,\n)\nchain = LLMChain(llm=chat, prompt=prompt, verbose=True)\n\nquestion = "What are Prem Benefits?"\ndocs = vectorstore.similarity_search(question)\ncontext = docs[0].page_content\nchain.run(question=question, context=context)\n')),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Example using Redis instead of Qdrant")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Using vicuna-7b-q4\nchat = ChatOpenAI(openai_api_base="http://localhost:8001/api/v1", max_tokens=128)\n\n# Using sentence transformers all-MiniLM-L6-v2\nembeddings = OpenAIEmbeddings(openai_api_base="http://localhost:8000/api/v1")\n\n# Using locally running Redis\nurl = "redis://localhost:6379"\n\nrds = Redis.from_documents(docs, embeddings, redis_url=url,  index_name="prem_index_test")\n\nquery = "What are Prem Benefits?"\ndocs = vectorstore.similarity_search(query)\nprint(docs[0].page_content)\n')),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Perform the Query")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'template = """\nYou are an AI assistant for answering questions about Prem.\nProvide a conversational answer to the question based on the following docouments found using semantic search. Be original, concice, accurate and helpful.\n\nQuestion: {question}\n=========\nContext: {context}\n=========\nAnswer in Markdown:\n"""  # noqa E501\nprompt = PromptTemplate(\n    input_variables=["question", "context"],\n    template=template,\n)\nchain = LLMChain(llm=chat, prompt=prompt, verbose=True)\n\nquestion = "What are Prem Benefits?"\ndocs = vectorstore.similarity_search(question)\ncontext = docs[0].page_content\nchain.run(question=question, context=context)\n')))}m.isMDXComponent=!0}}]);